{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-19-db193d01385d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-db193d01385d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    The objective of this assignment is to get you familiarizewith  the  problems  of  `classification`  and  `verification`with a popular problem space of `face`\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Assignment 2\n",
    "The objective of this assignment is to get you familiarizewith  the  problems  of  `classification`  and  `verification`with a popular problem space of `face`\n",
    "\n",
    "This jupyter notebook is meant to be used in conjunction with the full questions in the assignment pdf.\n",
    "\n",
    "## Instructions\n",
    "- Write your code and analyses in the indicated cells.\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Do not attempt to change the contents of the other cells.\n",
    "\n",
    "## Allowed Libraries\n",
    "- All libraries are allowed \n",
    "\n",
    "## Datasets \n",
    "- 3 datasets are provided. Load the data from the drive [link](!https://drive.google.com/file/d/1ujsKv9W5eidb4TXt1pnsqwDKVDFtzZTh/view?usp=sharing).\n",
    "- Unzip the downloaded file and store the files in a folder called `datasets`. Keep the `datasets` folder in the same directory as of the jupyter notebook \n",
    "\n",
    "## Submission\n",
    "- Ensure that this notebook runs without errors when the cells are run in sequence.\n",
    "- Rename the notebook to `<roll_number>.ipynb` and submit ONLY the notebook file on moodle.\n",
    "- Upload  the  notebook,  report  and  classification  results as a zip file to moodle. Name the zip file as `<rollnumber>_assignment2.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. A future version of pip will drop support for Python 2.7. More details about Python 2 support in pip, can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scikit-learn in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (0.20.4)\n",
      "Requirement already satisfied: matplotlib in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (2.2.5)\n",
      "Requirement already satisfied: Pillow in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (6.2.2)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from scikit-learn) (1.16.6)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from scikit-learn) (1.2.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from matplotlib) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: six>=1.10 in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from matplotlib) (1.12.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from matplotlib) (2.4.7)\n",
      "Requirement already satisfied: subprocess32 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from matplotlib) (3.5.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from matplotlib) (2.8.1)\n",
      "Requirement already satisfied: backports.functools-lru-cache in /Users/Furqan/Library/Python/2.7/lib/python/site-packages (from matplotlib) (1.6.1)\n",
      "Requirement already satisfied: pytz in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from matplotlib) (2013.7)\n",
      "Requirement already satisfied: setuptools in /System/Library/Frameworks/Python.framework/Versions/2.7/Extras/lib/python (from kiwisolver>=1.0.1->matplotlib) (41.0.1)\n"
     ]
    }
   ],
   "source": [
    "# Installing Libraries\n",
    "!pip install scikit-learn matplotlib Pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Imports\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as  np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "\n",
    "# Loading and plotting data\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt \n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Features\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "from sklearn.discriminant_analysis import _class_means,_class_cov\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "- Image size: Bigger images create better representation but would require more computation. Choose the correct image size based on your Laptop configuration. \n",
    "- is_grayscale: Should you take grayscale images? Or rgb images? Choose whichever gives better representation for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = {\n",
    "    'image_size': 32,\n",
    "    'is_grayscale': False,\n",
    "    'val_split': 0.75\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "cfw_dict = {'Amitabhbachan': 0,\n",
    "    'AamirKhan': 1,\n",
    "    'DwayneJohnson': 2,\n",
    "    'AishwaryaRai': 3,\n",
    "    'BarackObama': 4,\n",
    "    'NarendraModi': 5,\n",
    "    'ManmohanSingh': 6,\n",
    "    'VladimirPutin': 7}\n",
    "\n",
    "imfdb_dict = {'MadhuriDixit': 0,\n",
    "     'Kajol': 1,\n",
    "     'SharukhKhan': 2,\n",
    "     'ShilpaShetty': 3,\n",
    "     'AmitabhBachan': 4,\n",
    "     'KatrinaKaif': 5,\n",
    "     'AkshayKumar': 6,\n",
    "     'Amir': 7}\n",
    "\n",
    "# Load Image using PIL for dataset\n",
    "def load_image(path):\n",
    "    im = Image.open(path).convert('L' if opt['is_grayscale'] else 'RGB')\n",
    "    im = im.resize((opt['image_size'],opt['image_size']))\n",
    "    im = np.array(im)\n",
    "    im = im/256\n",
    "    return im\n",
    "\n",
    "# Load the full data from directory\n",
    "def load_data(dir_path):\n",
    "    image_list = []\n",
    "    y_list = []\n",
    "    \n",
    "    if \"CFW\" in dir_path:\n",
    "        label_dict = cfw_dict\n",
    "\n",
    "    elif \"yale\" in dir_path.lower():\n",
    "        label_dict = {}\n",
    "        for i in range(15):\n",
    "            label_dict[str(i+1)] = i\n",
    "    elif \"IMFDB\" in dir_path:\n",
    "        label_dict = imfdb_dict\n",
    "    else:\n",
    "        raise KeyError(\"Dataset not found.\")\n",
    "    \n",
    "    \n",
    "    for filename in sorted(os.listdir(dir_path)):\n",
    "        if filename.endswith(\".png\"):\n",
    "            im = load_image(os.path.join(dir_path,filename))\n",
    "            y = filename.split('_')[0]\n",
    "            y = label_dict[y] \n",
    "            image_list.append(im)\n",
    "            y_list.append(y)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    image_list = np.array(image_list)\n",
    "    y_list = np.array(y_list)\n",
    "\n",
    "    print(\"Dataset shape:\",image_list.shape)\n",
    "\n",
    "    return image_list,y_list\n",
    "\n",
    "# Display N Images in a nice format\n",
    "def disply_images(imgs,classes,row=1,col=2,w=64,h=64):\n",
    "    fig=plt.figure(figsize=(8, 8))\n",
    "    for i in range(1, col*row +1):\n",
    "        img = imgs[i-1]\n",
    "        fig.add_subplot(row, col, i)\n",
    "        \n",
    "        if opt['is_grayscale']:\n",
    "            plt.imshow(img , cmap='gray') \n",
    "        else:\n",
    "            plt.imshow(img)\n",
    "        \n",
    "        plt.title(\"Class:{}\".format(classes[i-1]))\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Dataset shape:', (672, 32, 32, 3))\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "# eg.\n",
    "dirpath = './dataset/IIIT-CFW/'\n",
    "X,y = load_data(dirpath)\n",
    "N,H,W = X.shape[0:3]\n",
    "C = 1 if opt['is_grayscale'] else X.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show sample images\n",
    "ind = np.random.randint(0,y.shape[0],6)\n",
    "disply_images(X[ind,...],y[ind], row=2,col=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "    You are provided 6 Features. These features are:\n",
    "   - Eigen Faces / PCA \n",
    "   - Kernel PCA\n",
    "   - Fisher Face / LDA\n",
    "   - Kernel Fisher Face\n",
    "   - VGG Features \n",
    "   - Resnet Features\n",
    "\n",
    "**VGG and Resnet features are last layer features learned by training a model for image classification**\n",
    "    \n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Flatten to apply PCA/LDA\n",
    "X = X.reshape((N,H*W*C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Eigen Face:\n",
    "Use principal component analysis to get the eigen faces. \n",
    "Go through the [documentation](!http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) on how to use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pca(X,k):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "    \"\"\"\n",
    "    pca = PCA(n_components=k)\n",
    "    X_k = pca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Kernel Face:\n",
    "Use Kernel principal component analysis to get the eigen faces. \n",
    "\n",
    "There are different kernels that can be used. Eg. Poly, rbf, sigmoid. Choose the whichever gives the best result or representation. See [link](!https://data-flair.training/blogs/svm-kernel-functions/) for better understanding of these kernels  \n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.KernelPCA.html#sklearn.decomposition.KernelPCA) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_pca(X, k,kernel='rbf', degree=3):\n",
    "    \"\"\"\n",
    "        Get PCA of K dimension using the top eigen vectors \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use (“linear” | “poly” | “rbf” | “sigmoid” | “cosine” )\n",
    "        @param: d => Degree for poly kernels. Ignored by other kernels\n",
    "    \"\"\"\n",
    "    kpca = KernelPCA(n_components=k,kernel=kernel,degree=degree)\n",
    "    X_k = kpca.fit_transform(X)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fisher Face\n",
    "Another method similar to the eigenface technique is `fisherfaces` which uses linear discriminant analysis.\n",
    "This method for facial recognition is less sensitive to variation in lighting and pose of the face than using eigenfaces. Fisherface uses labelled data to retain more of the class-specific information during the dimension reduction stage.\n",
    "\n",
    "Go through the [documentation](!https://scikit-learn.org/stable/modules/generated/sklearn.discriminant_analysis.LinearDiscriminantAnalysis.html) on how to use it different kernels in Sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda(X,y, k):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "    \"\"\"\n",
    "    lda = LDA(n_components=k)\n",
    "    X_k = lda.fit_transform(X,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Kernel Fisher Face\n",
    "Use LDA using different kernels similiar to KernelPCA. Here the input is directly transformed instead of using the kernel trick.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kernel_lda(X,y,k,kernel='rbf',degree=3):\n",
    "    \"\"\"\n",
    "        Get LDA of K dimension \n",
    "        @param: X => Your data flattened to D dimension\n",
    "        @param: k => Number of components\n",
    "        @param: kernel => which kernel to use ( “poly” | “rbf” | “sigmoid”)\n",
    "    \"\"\"\n",
    "    # Transform  input\n",
    "    if kernel == \"poly\":\n",
    "        X_transformed = X**degree\n",
    "    elif kernel == \"rbf\":\n",
    "        var = np.var(X)\n",
    "        X_transformed= np.exp(-X/(2*var))\n",
    "    elif kernel == \"sigmoid\":\n",
    "        X_transformed = np.tanh(X)\n",
    "    else: \n",
    "        raise NotImplementedError(\"Kernel {} Not defined\".format(kernel))\n",
    "        \n",
    "    klda = LDA(n_components=k)\n",
    "    X_k = klda.fit_transform(X,y)\n",
    "    return X_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. VGG Features\n",
    "VGG Neural Networks a 19 layer CNN architecture introduced by Andrew Zisserman([Link](!https://arxiv.org/pdf/1409.1556.pdf) to paper). We are providing you with the last fully connected layer of this model.\n",
    "\n",
    "The model was trained for face classification on each dataset and each feature the dimension of 4096."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"VGG19_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Resnet Features\n",
    "\n",
    "[Residual neural networks](!https://arxiv.org/pdf/1512.03385.pdf) are CNN with large depth, to effectively train these netwrorks they utilize skip connections, or short-cuts to jump over some layers. This helps solving [vanishing gradient problem](!https://en.wikipedia.org/wiki/Vanishing_gradient_problem) \n",
    "\n",
    "A 50 layer resnet model was trained for face classification on each dataset. Each feature the dimension of 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_resnet_features(dirpath):\n",
    "    features = np.load(os.path.join(dirpath,\"resnet50_features.npy\"))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "\n",
    "1(a). What are eigen faces? \n",
    "\n",
    "___________________________\n",
    "\n",
    "Your answers here (double click to edit)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(b).  How many eigen vec-tors/faces are required to “satisfactorily” reconstruct a  person  in  these  three  datasets? (Don’t  forget  to make your argument based on eigen value spectrum) Show appropriate graphs, qualitative examples andmake a convincing argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute your features \n",
    "# eg.\n",
    "# X_3D = get_kernel_lda(X,y,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot  \n",
    "# eg.\n",
    "# fig = plt.figure(figsize=(8,8))\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(X_3D[:,0],X_3D[:,1],X_3D[:,2],c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the eigen value spectrum "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(c). Reconstruct  the  image  back for each case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_images(<input_parameters>,*args,**kwargs):\n",
    "    \"\"\"\n",
    "        Reconstruct the images back by just using the selected principal components. \n",
    "\n",
    "\n",
    "        You have to write the code in this code block.\n",
    "        You can change the functions provided above (eg, get_pca, get_lda) for your use case. \n",
    "            \n",
    "        @params: \n",
    "                Input parameters\n",
    "\n",
    "        @return reconstructed_X => reconstructed image\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    pass\n",
    "    reconstruct_X = None\n",
    "    \n",
    "    return reconstruct_X    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results \n",
    "# X_reconstruced = reconstruct_images()\n",
    "\n",
    "# Display random images\n",
    "# ind = np.random.randint(0,y.shape[0],6)\n",
    "# disply_images(X_reconstruced_3D[ind,...],y[ind],row=2,col=3)\n",
    "\n",
    "# Show the reconstruction error\n",
    "print(np.sqrt(np.mean((X - X_reconstructed)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1(d). Which person/identity is difficult to represent com-pactly with fewer eigen vectors?  Why is that?  Explain with your empirical observations and intuitive answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2(a). Use any classifier(MLP, Logistic regression, SVM, Decision Trees) and find the classification accuracy. \n",
    "\n",
    "2(b)Which method works well? Do a comparitivestudy. \n",
    "\n",
    "\n",
    "You already know the paper [Face Recognition Us-ing  Kernel  Methods](!http://face-rec.org/algorithms/Kernel/nips01.pdf) .See  this  as  an  example for empirical analysis of different features/classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your classifier here. You can use libraries like sklearn to create your classifier \n",
    "\n",
    "class Classifier():\n",
    "    def __init__():\n",
    "        super.__init__()\n",
    "    \n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def classify(self,X):\n",
    "        \"\"\"\n",
    "            Given an input X classify it into appropriate class. \n",
    "        \"\"\"\n",
    "        \n",
    "        return prediction\n",
    "        \n",
    "    def confusion_matrix(self,pred,y):\n",
    "        \"\"\"\n",
    "            A confusion matrix is a table that is often used to describe the performance of a classification\n",
    "            model (or “classifier”) on a set of test data for which the true values are known.\n",
    "            \n",
    "            \n",
    "            @return confusion_matrix => num_classesxnum_classes martix \n",
    "                where confusion_matrix[i,j] = number of prediction which are i and number of ground truth value equal j \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is the classifier on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters and judge the classification\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your classifier validated. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "\n",
    "        # Create a confusion matrix\n",
    "        \n",
    "        # Calculate Validation accuracy \n",
    "    \n",
    "        # Calculate precision and recall \n",
    "        \n",
    "        # Calculate F1-score\n",
    "    \n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train and validation split to train your classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, classification error, accuracy, f1-score\n",
    "\n",
    "# Print the table. (You can use Pandas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each dataset print the confusion matrix for the best model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Similiar to 1(b) use t-SNE based visilization of faces?  Does it makesense?  Do you see similar people coming together?or something else?  Can you do visualization datasetwise and combined? Here you will use a popular implementation.(Worth  reading and understanding  t-SNE.  We  will not discuss it in the class and out of scope for thiscourse/exams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute TSNE for different features and create a scatter plot\n",
    "\n",
    "X =  # feature \n",
    "k = 3 # Number of components in TSNE\n",
    "\n",
    "# Compute\n",
    "X_TSNE = TSNE(n_components=k).fit_transform(X)\n",
    "\n",
    "\n",
    "# Plot the representation in 2d/3d\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.`face`  is  used  for  verification.   \n",
    "\n",
    "4(a) How do we formulate the problem using KNN \n",
    "\n",
    "4(b) How do we analyze the performance ? suggest  the  metrics  (like  accuracy) that is appropriate for this task.\n",
    "\n",
    "_______________________________________________________________________\n",
    "\n",
    "4(c)Show empirical re-sults  with  all  the  representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceVerification():\n",
    "    def __init__():\n",
    "        super.__init__()\n",
    "    \n",
    "    # Define your parameters eg, W,b, max_iterations etc. \n",
    "    \n",
    "    def verify(self,X,class_id):\n",
    "        \"\"\"\n",
    "            Given an input X find if the class id is correct or not.\n",
    "            \n",
    "            @return verfication_results => N vector containing True or False. \n",
    "                    If the class-id matches with your prediction then true else false.   \n",
    "        \"\"\"\n",
    "        \n",
    "        return verfication_results\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        \"\"\"\n",
    "            Given your training data, learn the parameters of your classifier\n",
    "            \n",
    "            @param X_train => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                it is the data on which your verification system will be trained. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_train => N vector. Ground truth label \n",
    "    \n",
    "            @return Nothing\n",
    "        \"\"\"\n",
    "        \n",
    "    def validate(self,X_validate,y_validate):\n",
    "        \"\"\"\n",
    "            How good is your system on unseen data? Use the function below to calculate different metrics. \n",
    "            Based on these matrix change the hyperparmeters\n",
    "            \n",
    "            @param X_validate => NxD tensor. Where N is the number of samples and D is the dimension. \n",
    "                                It can be any combination of features provided above.\n",
    "\n",
    "            @param y_validate => N vector. Ground truth label \n",
    "            \n",
    "        \"\"\"\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train and validation split and show your results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 tables simiar to page-6 of the paper. One table per dataset \n",
    "# Each table will have 5 columns. \n",
    "# Feature/combination of feature used, reduced dimension space, verification error, accuracy, precision\n",
    "\n",
    "# Print the table. (You can use Pandas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extenstion / Application\n",
    "    Create a system for any one of the following problems:\n",
    "\n",
    "- Politicians  vs  Filmstars  in  a  public  data  set.   (eg.LFW)\n",
    "        You already have seen IIIT-CFW dataset. Use it for classification. \n",
    "- Age prediction\n",
    "        Given different actors/actress in IMFDB create new labels based on their age.  \n",
    "- Gender prediction\n",
    "        Given different actors/actress in IMFDB+IIIT-CFW create new labels based on their gender.\n",
    "- Emotion classification\n",
    "        Both the yale dataset and IMFDB contain an `emotion.txt` file. Using that you can create a emotion predicter \n",
    "- cartoon vs real images\n",
    "        Use a combination of IIIT-CFW and other dataset. \n",
    "        \n",
    "\n",
    "\n",
    "You are free to use a new dataset that is publicly avail-able or even create one by crawling from internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your classifier\n",
    "\n",
    "# Validate your classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show qualitative results such as accuracy, k-fold validation, TSNE/PCA/Isomap plots, etc.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show quantitative results such as examples of correct prediction and wrong prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
